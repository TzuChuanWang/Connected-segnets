{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "from data import *\n",
    "from nets.MaxPoolingWithIndices2D import MaxPoolingWithIndices2D\n",
    "from nets.MaxUnpoolingWithIndices2D import MaxUnpoolingWithIndices2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SegNet(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    论文中介绍的SegNet网络\n",
    "    :param input_shape: 模型输入shape\n",
    "    :param num_classes: 分类数量\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # encoder\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x, mask_1 = MaxPoolingWithIndices2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x, mask_2 = MaxPoolingWithIndices2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x, mask_3 = MaxPoolingWithIndices2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x, mask_4 = MaxPoolingWithIndices2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x, mask_5 = MaxPoolingWithIndices2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # decoder\n",
    "    x = MaxUnpoolingWithIndices2D((2, 2))([x, mask_5])\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = MaxUnpoolingWithIndices2D((2, 2))([x, mask_4])\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = MaxUnpoolingWithIndices2D((2, 2))([x, mask_3])\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = MaxUnpoolingWithIndices2D((2, 2))([x, mask_2])\n",
    "    x = layers.Convolution2D(128, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Convolution2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = MaxUnpoolingWithIndices2D((2, 2))([x, mask_1])\n",
    "    x = layers.Convolution2D(64, (3, 3), padding='same', kernel_initializer='he_uniform')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), padding='valid',activation=\"sigmoid\", kernel_initializer='he_uniform')(x)\n",
    "\n",
    "    #     x = layers.Conv2D(num_classes, (1, 1), padding='valid', kernel_initializer='he_uniform')(x)\n",
    "#     outputs = layers.BatchNormalization()(x)\n",
    "\n",
    "#     import os \n",
    "#     os.environ['KERAS_BACKEND']='tensorflow'\n",
    "#     import tensorflow.python.keras.backend as K\n",
    "#     def dice_coef(y_true, y_pred, smooth=1):\n",
    "#         y_true_f = K.flatten(y_true)\n",
    "#         y_pred_f = K.flatten(y_pred)\n",
    "#         intersection = K.sum(y_true_f * y_pred_f)\n",
    "#         return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "#     def dice_loss(y_true, y_pred):\n",
    "#         loss = dice_coef(y_true, y_pred)\n",
    "#         return loss\n",
    "    \n",
    "#     def dice_coef_loss(y_true, y_pred):\n",
    "#         return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "        \n",
    "        # outputs = layers.Activation('softmax')(x)\n",
    "    \n",
    "    segnet_model = models.Model(inputs=inputs, outputs=outputs, name='SegNet')\n",
    "    \n",
    "    return segnet_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Define functions to evaluate the output\n",
    "import sklearn.metrics as sm\n",
    "\n",
    "def get_confusion_matrix_elements(groundtruth_list, predicted_list):\n",
    "\n",
    "    tn, fp, fn, tp = sm.confusion_matrix(groundtruth_list, predicted_list,labels=[0,1]).ravel()\n",
    "    tn, fp, fn, tp = np.float64(tn), np.float64(fp), np.float64(fn), np.float64(tp)\n",
    "\n",
    "    return tn, fp, fn, tp\n",
    "\n",
    "def get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list):\n",
    "\n",
    "    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n",
    "    \n",
    "    total = tp + fp + fn + tn\n",
    "    accuracy = (tp + tn) / total\n",
    "    prec=tp/(tp+fp)\n",
    "    rec=tp/(tp+fn)\n",
    "    IoU=tp/(tp+fp+fn)\n",
    "    \n",
    "    return prec,rec,IoU,accuracy\n",
    "\n",
    "def get_f1_score(groundtruth_list, predicted_list):\n",
    "\n",
    "    tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n",
    "    \n",
    "    f1_score = (2 * tp) / ((2 * tp) + fp + fn)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "def get_validation_metrics(groundtruth,predicted):\n",
    "    u,v=np.shape(groundtruth)\n",
    "    groundtruth_list=np.reshape(groundtruth,(u*v,))\n",
    "    predicted_list=np.reshape(predicted,(u*v,))\n",
    "    prec,rec,IoU,acc=get_prec_rec_IoU_accuracy(groundtruth_list, predicted_list)\n",
    "    f1_score=get_f1_score(groundtruth_list, predicted_list)\n",
    "   # print(\"Precision=\",prec, \"Recall=\",rec, \"IoU=\",IoU, \"acc=\",acc, \"F1=\",f1_score)\n",
    "    return prec,rec,IoU,acc,f1_score\n",
    "\n",
    "def evalResult(gth_path,npyfile,target_size=(512,512),flag_multi_class = False,num_class = 2):\n",
    "    files=sorted(os.listdir(gth_path))\n",
    "    print(files)\n",
    "    prec=0\n",
    "    rec=0\n",
    "    acc=0\n",
    "    IoU=0\n",
    "    f1_score=0\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = item[:,:,0]\n",
    "        gth = io.imread(os.path.join(gth_path,files[i]))\n",
    "        gth = trans.resize(gth,target_size)\n",
    "        img1=np.array(((img - np.min(img))/np.ptp(img))>0.1).astype(float)\n",
    "        gth1=np.array(((gth - np.min(gth))/np.ptp(gth))>0.1).astype(float)\n",
    "        p,r,I,a,f=get_validation_metrics(gth1,img1)\n",
    "        prec=prec+p\n",
    "        rec=rec+r\n",
    "        acc=acc+a\n",
    "        IoU=IoU+I\n",
    "        f1_score=f1_score+f\n",
    "    print(\"Precision=\",prec/(i+1), \"Recall=\",rec/(i+1), \"IoU=\",IoU/(i+1), \"acc=\",acc/(i+1), \"F1=\",f1_score/(i+1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your Unet with membrane data\n",
    "membrane data is in folder membrane/, it is a binary classification task.\n",
    "\n",
    "The input shape of image and mask are the same :(batch_size,rows,cols,channel = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras.backend as K\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1-dice_coef(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "#model.compile(optimizer = Adam(lr = 1e-6), loss = 'binary_crossentropy', metrics = 'accuracy')\n",
    "model = SegNet((512,512,1),1)\n",
    "model.compile(optimizer = Adam(lr = 1e-6), loss = [dice_loss], metrics = 'binary_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 1 classes.\n",
      "Found 20 images belonging to 1 classes.\n",
      "Found 73 images belonging to 1 classes.\n",
      "Found 73 images belonging to 1 classes.\n",
      "Epoch 1/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9581 - binary_accuracy: 0.8557\n",
      "Epoch 00001: val_loss improved from inf to 0.93921, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.9581 - binary_accuracy: 0.8557 - val_loss: 0.9392 - val_binary_accuracy: 0.9682\n",
      "Epoch 2/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9172 - binary_accuracy: 0.8374\n",
      "Epoch 00002: val_loss did not improve from 0.93921\n",
      "2000/2000 [==============================] - 559s 280ms/step - loss: 0.9172 - binary_accuracy: 0.8374 - val_loss: 0.9405 - val_binary_accuracy: 0.9687\n",
      "Epoch 3/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8990 - binary_accuracy: 0.8535\n",
      "Epoch 00003: val_loss did not improve from 0.93921\n",
      "2000/2000 [==============================] - 557s 278ms/step - loss: 0.8990 - binary_accuracy: 0.8535 - val_loss: 0.9433 - val_binary_accuracy: 0.9688\n",
      "Epoch 4/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8845 - binary_accuracy: 0.8756\n",
      "Epoch 00004: val_loss did not improve from 0.93921\n",
      "2000/2000 [==============================] - 557s 279ms/step - loss: 0.8845 - binary_accuracy: 0.8756 - val_loss: 0.9490 - val_binary_accuracy: 0.9688\n",
      "Epoch 5/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8735 - binary_accuracy: 0.8931\n",
      "Epoch 00005: val_loss did not improve from 0.93921\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.8735 - binary_accuracy: 0.8931 - val_loss: 0.9488 - val_binary_accuracy: 0.9687\n",
      "Epoch 6/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8616 - binary_accuracy: 0.9069\n",
      "Epoch 00006: val_loss did not improve from 0.93921\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.8616 - binary_accuracy: 0.9069 - val_loss: 0.9592 - val_binary_accuracy: 0.9636\n",
      "Epoch 7/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8501 - binary_accuracy: 0.9206\n",
      "Epoch 00007: val_loss improved from 0.93921 to 0.89284, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 557s 279ms/step - loss: 0.8501 - binary_accuracy: 0.9206 - val_loss: 0.8928 - val_binary_accuracy: 0.9564\n",
      "Epoch 8/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8390 - binary_accuracy: 0.9320\n",
      "Epoch 00008: val_loss improved from 0.89284 to 0.77795, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.8390 - binary_accuracy: 0.9320 - val_loss: 0.7780 - val_binary_accuracy: 0.9514\n",
      "Epoch 9/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8264 - binary_accuracy: 0.9420\n",
      "Epoch 00009: val_loss improved from 0.77795 to 0.72847, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.8264 - binary_accuracy: 0.9420 - val_loss: 0.7285 - val_binary_accuracy: 0.9478\n",
      "Epoch 10/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8160 - binary_accuracy: 0.9502\n",
      "Epoch 00010: val_loss improved from 0.72847 to 0.70033, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 557s 278ms/step - loss: 0.8160 - binary_accuracy: 0.9502 - val_loss: 0.7003 - val_binary_accuracy: 0.9366\n",
      "Epoch 11/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8026 - binary_accuracy: 0.9570\n",
      "Epoch 00011: val_loss improved from 0.70033 to 0.68806, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.8026 - binary_accuracy: 0.9570 - val_loss: 0.6881 - val_binary_accuracy: 0.9331\n",
      "Epoch 12/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7923 - binary_accuracy: 0.9610\n",
      "Epoch 00012: val_loss did not improve from 0.68806\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.7923 - binary_accuracy: 0.9610 - val_loss: 0.6891 - val_binary_accuracy: 0.9279\n",
      "Epoch 13/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7812 - binary_accuracy: 0.9650\n",
      "Epoch 00013: val_loss improved from 0.68806 to 0.68035, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 557s 278ms/step - loss: 0.7812 - binary_accuracy: 0.9650 - val_loss: 0.6803 - val_binary_accuracy: 0.9263\n",
      "Epoch 14/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7688 - binary_accuracy: 0.9684\n",
      "Epoch 00014: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 0.7688 - binary_accuracy: 0.9684 - val_loss: 0.6863 - val_binary_accuracy: 0.9260\n",
      "Epoch 15/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7571 - binary_accuracy: 0.9708\n",
      "Epoch 00015: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.7571 - binary_accuracy: 0.9708 - val_loss: 0.7102 - val_binary_accuracy: 0.9178\n",
      "Epoch 16/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7470 - binary_accuracy: 0.9730\n",
      "Epoch 00016: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 0.7470 - binary_accuracy: 0.9730 - val_loss: 0.6863 - val_binary_accuracy: 0.9133\n",
      "Epoch 17/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7335 - binary_accuracy: 0.9750\n",
      "Epoch 00017: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.7335 - binary_accuracy: 0.9750 - val_loss: 0.6991 - val_binary_accuracy: 0.9234\n",
      "Epoch 18/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7234 - binary_accuracy: 0.9767\n",
      "Epoch 00018: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.7234 - binary_accuracy: 0.9767 - val_loss: 0.7062 - val_binary_accuracy: 0.8952\n",
      "Epoch 19/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7114 - binary_accuracy: 0.9783\n",
      "Epoch 00019: val_loss did not improve from 0.68035\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.7114 - binary_accuracy: 0.9783 - val_loss: 0.6894 - val_binary_accuracy: 0.9057\n",
      "Epoch 20/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.7009 - binary_accuracy: 0.9796\n",
      "Epoch 00020: val_loss improved from 0.68035 to 0.67400, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 0.7009 - binary_accuracy: 0.9796 - val_loss: 0.6740 - val_binary_accuracy: 0.9179\n",
      "Epoch 21/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6856 - binary_accuracy: 0.9812\n",
      "Epoch 00021: val_loss did not improve from 0.67400\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 0.6856 - binary_accuracy: 0.9812 - val_loss: 0.6787 - val_binary_accuracy: 0.9083\n",
      "Epoch 22/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6768 - binary_accuracy: 0.9820\n",
      "Epoch 00022: val_loss did not improve from 0.67400\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.6768 - binary_accuracy: 0.9820 - val_loss: 0.6865 - val_binary_accuracy: 0.9168\n",
      "Epoch 23/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6623 - binary_accuracy: 0.9831\n",
      "Epoch 00023: val_loss did not improve from 0.67400\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 0.6623 - binary_accuracy: 0.9831 - val_loss: 0.7050 - val_binary_accuracy: 0.8946\n",
      "Epoch 24/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6503 - binary_accuracy: 0.9837\n",
      "Epoch 00024: val_loss improved from 0.67400 to 0.65586, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.6503 - binary_accuracy: 0.9837 - val_loss: 0.6559 - val_binary_accuracy: 0.9239\n",
      "Epoch 25/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6404 - binary_accuracy: 0.9846\n",
      "Epoch 00025: val_loss did not improve from 0.65586\n",
      "2000/2000 [==============================] - 555s 277ms/step - loss: 0.6404 - binary_accuracy: 0.9846 - val_loss: 0.6683 - val_binary_accuracy: 0.9204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6264 - binary_accuracy: 0.9853\n",
      "Epoch 00026: val_loss did not improve from 0.65586\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.6264 - binary_accuracy: 0.9853 - val_loss: 0.6999 - val_binary_accuracy: 0.8977\n",
      "Epoch 27/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6139 - binary_accuracy: 0.9858\n",
      "Epoch 00027: val_loss did not improve from 0.65586\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 0.6139 - binary_accuracy: 0.9858 - val_loss: 0.6647 - val_binary_accuracy: 0.9138\n",
      "Epoch 28/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6017 - binary_accuracy: 0.9867\n",
      "Epoch 00028: val_loss did not improve from 0.65586\n",
      "2000/2000 [==============================] - 555s 277ms/step - loss: 0.6017 - binary_accuracy: 0.9867 - val_loss: 0.6592 - val_binary_accuracy: 0.9297\n",
      "Epoch 29/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5907 - binary_accuracy: 0.9872\n",
      "Epoch 00029: val_loss improved from 0.65586 to 0.64104, saving model to unet_membrane_hospital_try.hdf5\n",
      "2000/2000 [==============================] - 555s 277ms/step - loss: 0.5907 - binary_accuracy: 0.9872 - val_loss: 0.6410 - val_binary_accuracy: 0.9315\n",
      "Epoch 30/1000\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.5759 - binary_accuracy: 0.9879\n",
      "Epoch 00030: val_loss did not improve from 0.64104\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 0.5759 - binary_accuracy: 0.9879 - val_loss: 0.6691 - val_binary_accuracy: 0.9316\n",
      "Epoch 31/1000\n",
      " 568/2000 [=======>......................] - ETA: 6:36 - loss: 0.5702 - binary_accuracy: 0.9881"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f21eb6bd6326>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m history=model.fit(myGene,steps_per_epoch=2000,epochs=1000,validation_data=(valdata_image,valdata_mask),\n\u001b[1;32m---> 15\u001b[1;33m                             callbacks=[mycallback])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_gen_args = dict(rotation_range=0.2,\n",
    "#                     width_shift_range=0.05,\n",
    "#                     height_shift_range=0.05,\n",
    "#                     shear_range=0.05,\n",
    "#                     zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'data/membrane_hospital/train','image','label',data_gen_args,save_to_dir = None)\n",
    "valdata_image,valdata_mask = valGenerator(2,'data/membrane_hospital/val','image','label',data_gen_args)\n",
    "mycallback = [tf.keras.callbacks.EarlyStopping(patience=10, monitor = 'val_loss'),\n",
    "              ModelCheckpoint('unet_membrane_hospital_try.hdf5', monitor='val_loss',verbose=1, save_weights_only=True,save_best_only=True)]\n",
    "#model = SegNet((512,512,1),2)\n",
    "#model_checkpoint = ModelCheckpoint('unet_membrane.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "history=model.fit(myGene,steps_per_epoch=2000,epochs=1000,validation_data=(valdata_image,valdata_mask),\n",
    "                            callbacks=[mycallback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imgs_train,imgs_mask_train = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "#model.fit(imgs_train, imgs_mask_train, batch_size=2, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test your model and save predicted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-fdb95920899c>:4: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "30/30 [==============================] - 6s 213ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\DaDa\\Desktop\\unet-master_segnet\\data.py:160: UserWarning: ./data/membrane_hospital/test/pred/1_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\DaDa\\Desktop\\unet-master_segnet\\data.py:160: UserWarning: ./data/membrane_hospital/test/pred/2_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\DaDa\\Desktop\\unet-master_segnet\\data.py:160: UserWarning: ./data/membrane_hospital/test/pred/13_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "C:\\Users\\DaDa\\Desktop\\unet-master_segnet\\data.py:160: UserWarning: ./data/membrane_hospital/test/pred/20_predict.png is a low contrast image\n",
      "  io.imsave(os.path.join(save_path,\"%d_predict.png\"%i),img)\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "testGene = testGenerator(\"data/membrane_hospital/test/\")\n",
    "model = SegNet((512,512,1),1)\n",
    "model.load_weights(\"unet_membrane_hospital_try.hdf5\")\n",
    "results = model.predict_generator(testGene,30,verbose=1)\n",
    "saveResult(\"./data/membrane_hospital/test/pred/\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PR_Result(gth_path,npyfile,target_size=(512,512),flag_multi_class = False,num_class = 2):\n",
    "    files=sorted(os.listdir(gth_path))\n",
    "    print(files)\n",
    "    AP=np.zeros(100)\n",
    "    for j in range(1, 99, 1):\n",
    "        AP[j]=0\n",
    "        for i,item in enumerate(npyfile):\n",
    "            img = item[:,:,0]\n",
    "            gth = io.imread(os.path.join(gth_path,files[i]))\n",
    "            gth = trans.resize(gth,target_size)\n",
    "            img1=np.array((img)>(j/1000)).astype(float)\n",
    "            gth1=np.array(gth>0.1).astype(float)\n",
    "            \n",
    "            u,v=np.shape(gth1)\n",
    "            groundtruth_list=np.reshape(gth1,(u*v,))\n",
    "            predicted_list=np.reshape(img1,(u*v,))\n",
    "            tn, fp, fn, tp = get_confusion_matrix_elements(groundtruth_list, predicted_list)\n",
    "            AP[j] = (tp/(tp+fn))+ AP[j]\n",
    "        AP[j] = AP[j]/(i+1)\n",
    "        print(\"AP[\",j,\"]=\",AP[j])\n",
    "            \n",
    "    return AP\n",
    "    \n",
    "#         p,r,I,a,f=get_validation_metrics(gth1,img1)\n",
    "#         prec=prec+p\n",
    "#         rec=rec+r\n",
    "#         acc=acc+a\n",
    "#         IoU=IoU+I\n",
    "#         f1_score=f1_score+f\n",
    "#     print(\"Precision=\",prec/(i+1), \"Recall=\",rec/(i+1), \"IoU=\",IoU/(i+1), \"acc=\",acc/(i+1), \"F1=\",f1_score/(i+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.png', '1.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '2.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '3.png', '4.png', '5.png', '6.png', '7.png', '8.png', '9.png']\n",
      "AP[ 1 ]= 0.9999699061248272\n",
      "AP[ 2 ]= 0.9977155514717936\n",
      "AP[ 3 ]= 0.9871247484967209\n",
      "AP[ 4 ]= 0.9671376279377896\n",
      "AP[ 5 ]= 0.9417268310473113\n",
      "AP[ 6 ]= 0.9091610546470019\n",
      "AP[ 7 ]= 0.8755328973815286\n",
      "AP[ 8 ]= 0.8408077281151455\n",
      "AP[ 9 ]= 0.8044084721224303\n",
      "AP[ 10 ]= 0.7719198245828037\n",
      "AP[ 11 ]= 0.7403293151088025\n",
      "AP[ 12 ]= 0.7102627646452306\n",
      "AP[ 13 ]= 0.5978641570140065\n",
      "AP[ 14 ]= 0.443083901322391\n",
      "AP[ 15 ]= 0.30759830150077483\n",
      "AP[ 16 ]= 0.19786142623350989\n",
      "AP[ 17 ]= 0.15867612358377592\n",
      "AP[ 18 ]= 0.14411027949590272\n",
      "AP[ 19 ]= 0.13275088403660806\n",
      "AP[ 20 ]= 0.12139439865468299\n",
      "AP[ 21 ]= 0.11242836059615446\n",
      "AP[ 22 ]= 0.10579672842943419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-2dbf3c4dd565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data/membrane_hospital/test/labelpng'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# evalResult(gt_path,results)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mAP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPR_Result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-40-6fd1788aa321>\u001b[0m in \u001b[0;36mPR_Result\u001b[1;34m(gth_path, npyfile, target_size, flag_multi_class, num_class)\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mgroundtruth_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgth1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mpredicted_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_confusion_matrix_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundtruth_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-338d33bdd9f3>\u001b[0m in \u001b[0;36mget_confusion_matrix_elements\u001b[1;34m(groundtruth_list, predicted_list)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mexample\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mhelper\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mdefinitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \"\"\"\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroundtruth_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;31m# convert yt, yp into index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;31m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf2.3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;31m# convert yt, yp into index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_to_ind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_labels\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;31m# intersect y_pred, y_true with labels, eliminate items not in labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gt_path='data/membrane_hospital/test/labelpng'\n",
    "# evalResult(gt_path,results)\n",
    "AP = PR_Result(gt_path,results)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1) # 建立圖表1\n",
    "plt.title('Precision/Recall Curve')# give plot a title\n",
    "plt.xlabel('Recall')# make axis labels\n",
    "plt.ylabel('Precision')\n",
    "\n",
    "#x、y都是列表，裡面存的分別是recall和precision\n",
    "#傳參得到或讀取檔案得到無所謂\n",
    "x=[]\n",
    "y=[]\n",
    "f=open('eval.txt','r')\n",
    "lines=f.readlines()\n",
    "for i in range(1, 99, 1):\n",
    "    y.append(AP[i])\n",
    "    x.append(i)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "plt.savefig('p-r.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./testjpg/\n",
      "directory： []\n",
      "file1： ['0.jpg', '1.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './testjpg/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "for file_name in filename_list:\n",
    "    original = Image.open('./testjpg/'+file_name)\n",
    "    img_name_temp = file_name.split(\".jpg\")\n",
    "    img_name_temp = img_name_temp[0] + '.png'\n",
    "    original = original.convert(\"L\")\n",
    "    original.save('testpng1/'+img_name_temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./data/membrane_hospital/test/pred/\n",
      "directory： []\n",
      "file1： ['0_predict.png', '10_predict.png', '11_predict.png', '12_predict.png', '13_predict.png', '14_predict.png', '15_predict.png', '16_predict.png', '17_predict.png', '18_predict.png', '19_predict.png', '1_predict.png', '20_predict.png', '21_predict.png', '22_predict.png', '23_predict.png', '24_predict.png', '25_predict.png', '26_predict.png', '27_predict.png', '28_predict.png', '29_predict.png', '2_predict.png', '3_predict.png', '4_predict.png', '5_predict.png', '6_predict.png', '7_predict.png', '8_predict.png', '9_predict.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './data/membrane_hospital/test/pred/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "    \n",
    "for file_name in filename_list:\n",
    "    img_name_temp = file_name.split(\"_predict\")\n",
    "    orignal = Image.open('./data/membrane_hospital/test/'+img_name_temp[0]+'.png')\n",
    "    w = orignal.width\n",
    "    h = orignal.height\n",
    "    mask = Image.open('./data/membrane_hospital/test/pred/'+file_name)\n",
    "    mask_new = mask.resize((w,h))\n",
    "    mask_new.save('./data/membrane_hospital/test/pred_resize/'+img_name_temp[0]+'_predictmask_resize.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./data/membrane_hospital/test/pred_resize/\n",
      "directory： []\n",
      "file1： ['0_predictmask_resize.png', '10_predictmask_resize.png', '11_predictmask_resize.png', '12_predictmask_resize.png', '13_predictmask_resize.png', '14_predictmask_resize.png', '15_predictmask_resize.png', '16_predictmask_resize.png', '17_predictmask_resize.png', '18_predictmask_resize.png', '19_predictmask_resize.png', '1_predictmask_resize.png', '20_predictmask_resize.png', '21_predictmask_resize.png', '22_predictmask_resize.png', '23_predictmask_resize.png', '24_predictmask_resize.png', '25_predictmask_resize.png', '26_predictmask_resize.png', '27_predictmask_resize.png', '28_predictmask_resize.png', '29_predictmask_resize.png', '2_predictmask_resize.png', '3_predictmask_resize.png', '4_predictmask_resize.png', '5_predictmask_resize.png', '6_predictmask_resize.png', '7_predictmask_resize.png', '8_predictmask_resize.png', '9_predictmask_resize.png']\n",
      "success0\n",
      "success10\n",
      "success11\n",
      "success12\n",
      "success13\n",
      "success14\n",
      "success15\n",
      "success16\n",
      "success17\n",
      "success18\n",
      "success19\n",
      "success1\n",
      "success20\n",
      "success21\n",
      "success22\n",
      "success23\n",
      "success24\n",
      "success25\n",
      "success26\n",
      "success27\n",
      "success28\n",
      "success29\n",
      "success2\n",
      "success3\n",
      "success4\n",
      "success5\n",
      "success6\n",
      "success7\n",
      "success8\n",
      "success9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './data/membrane_hospital/test/pred_resize/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "    \n",
    "for file_name in filename_list:\n",
    "    img_name_temp = file_name.split(\"_predict\")\n",
    "    original = Image.open('./data/membrane_hospital/test/pred_resize/'+file_name)\n",
    "    original = original.convert(\"RGBA\")\n",
    "    w = original.width\n",
    "    h = original.height\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            data = (original.getpixel((i,j)))#540,1215\n",
    "#             print (data)\n",
    "            if (data[0]>128 and data[1]>128 and data[2]>128):\n",
    "                original.putpixel((i,j),(0,128,255,100))\n",
    "            else :\n",
    "                original.putpixel((i,j),(255,255,255,0))\n",
    "    original.save('./data/membrane_hospital/test/temp/'+img_name_temp[0]+'_rgbapredictmask_resize.png')\n",
    "    print('success'+img_name_temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./data/membrane_hospital/test/pred_resize/\n",
      "directory： []\n",
      "file1： ['0_predictmask_resize.png', '10_predictmask_resize.png', '11_predictmask_resize.png', '12_predictmask_resize.png', '13_predictmask_resize.png', '14_predictmask_resize.png', '15_predictmask_resize.png', '16_predictmask_resize.png', '17_predictmask_resize.png', '18_predictmask_resize.png', '19_predictmask_resize.png', '1_predictmask_resize.png', '20_predictmask_resize.png', '21_predictmask_resize.png', '22_predictmask_resize.png', '23_predictmask_resize.png', '24_predictmask_resize.png', '25_predictmask_resize.png', '26_predictmask_resize.png', '27_predictmask_resize.png', '28_predictmask_resize.png', '29_predictmask_resize.png', '2_predictmask_resize.png', '3_predictmask_resize.png', '4_predictmask_resize.png', '5_predictmask_resize.png', '6_predictmask_resize.png', '7_predictmask_resize.png', '8_predictmask_resize.png', '9_predictmask_resize.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './data/membrane_hospital/test/pred_resize/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "    \n",
    "for file_name in filename_list:    \n",
    "    img_name_temp = file_name.split(\"_predict\")\n",
    "    imagea = Image.open('./data/membrane_hospital/test/'+img_name_temp[0]+'.png')\n",
    "    imageb = Image.open('./data/membrane_hospital/test/temp/'+img_name_temp[0]+'_rgbapredictmask_resize.png')\n",
    "    imagec = Image.open('./data/membrane_hospital/test/labeltemp/'+img_name_temp[0]+'_rgba_gt.png')\n",
    "    newimageb = imageb\n",
    "    imagea = imagea.convert(\"RGBA\")\n",
    "    #resultimage = Image.new('RGBA',imagea.size,(0,0,0,0))\n",
    "    resultimage = imagea\n",
    "    #resultimage.paste(imagea,(0,0))\n",
    "    resultimage.paste(newimageb,(0,0),newimageb)\n",
    "    resultimage.paste(imagec,(0,0),imagec)\n",
    "    resultimage.save('./data/membrane_hospital/test/visualresult/'+img_name_temp[0]+'_combinepredictmask.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##轉gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./data/membrane_hospital/test/label/\n",
      "directory： []\n",
      "file1： ['0.jpg', '1.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg']\n",
      "0.jpg\n",
      "success0\n",
      "1.jpg\n",
      "success1\n",
      "10.jpg\n",
      "success10\n",
      "11.jpg\n",
      "success11\n",
      "12.jpg\n",
      "success12\n",
      "13.jpg\n",
      "success13\n",
      "14.jpg\n",
      "success14\n",
      "15.jpg\n",
      "success15\n",
      "16.jpg\n",
      "success16\n",
      "17.jpg\n",
      "success17\n",
      "18.jpg\n",
      "success18\n",
      "19.jpg\n",
      "success19\n",
      "2.jpg\n",
      "success2\n",
      "20.jpg\n",
      "success20\n",
      "21.jpg\n",
      "success21\n",
      "22.jpg\n",
      "success22\n",
      "23.jpg\n",
      "success23\n",
      "24.jpg\n",
      "success24\n",
      "25.jpg\n",
      "success25\n",
      "26.jpg\n",
      "success26\n",
      "27.jpg\n",
      "success27\n",
      "28.jpg\n",
      "success28\n",
      "29.jpg\n",
      "success29\n",
      "3.jpg\n",
      "success3\n",
      "4.jpg\n",
      "success4\n",
      "5.jpg\n",
      "success5\n",
      "6.jpg\n",
      "success6\n",
      "7.jpg\n",
      "success7\n",
      "8.jpg\n",
      "success8\n",
      "9.jpg\n",
      "success9\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './data/membrane_hospital/test/label/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "    \n",
    "\n",
    "for file_name in filename_list:\n",
    "    img_name_temp = file_name.split(\".jpg\")\n",
    "    original = Image.open('./data/membrane_hospital/test/label/'+file_name)\n",
    "    print(file_name)\n",
    "    original = original.convert(\"RGBA\")\n",
    "    w = original.width\n",
    "    h = original.height\n",
    "    for i in range(0,w):\n",
    "        for j in range(0,h):\n",
    "            data = (original.getpixel((i,j)))#540,1215\n",
    "            #print (data)\n",
    "            if (data[0]==255 and data[1]==255 and data[2]==255):\n",
    "                original.putpixel((i,j),(255,0,0,100))\n",
    "            else :\n",
    "                original.putpixel((i,j),(255,255,255,0))\n",
    "    original.save('./data/membrane_hospital/test/labeltemp/'+img_name_temp[0]+'_rgba_gt.png')\n",
    "    print('success'+img_name_temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path： ./data/membrane_hospital/test/label/\n",
      "directory： []\n",
      "file1： ['0.jpg', '1.jpg', '10.jpg', '11.jpg', '12.jpg', '13.jpg', '14.jpg', '15.jpg', '16.jpg', '17.jpg', '18.jpg', '19.jpg', '2.jpg', '20.jpg', '21.jpg', '22.jpg', '23.jpg', '24.jpg', '25.jpg', '26.jpg', '27.jpg', '28.jpg', '29.jpg', '3.jpg', '4.jpg', '5.jpg', '6.jpg', '7.jpg', '8.jpg', '9.jpg']\n",
      "0.jpg\n",
      "success0\n",
      "1.jpg\n",
      "success1\n",
      "10.jpg\n",
      "success10\n",
      "11.jpg\n",
      "success11\n",
      "12.jpg\n",
      "success12\n",
      "13.jpg\n",
      "success13\n",
      "14.jpg\n",
      "success14\n",
      "15.jpg\n",
      "success15\n",
      "16.jpg\n",
      "success16\n",
      "17.jpg\n",
      "success17\n",
      "18.jpg\n",
      "success18\n",
      "19.jpg\n",
      "success19\n",
      "2.jpg\n",
      "success2\n",
      "20.jpg\n",
      "success20\n",
      "21.jpg\n",
      "success21\n",
      "22.jpg\n",
      "success22\n",
      "23.jpg\n",
      "success23\n",
      "24.jpg\n",
      "success24\n",
      "25.jpg\n",
      "success25\n",
      "26.jpg\n",
      "success26\n",
      "27.jpg\n",
      "success27\n",
      "28.jpg\n",
      "success28\n",
      "29.jpg\n",
      "success29\n",
      "3.jpg\n",
      "success3\n",
      "4.jpg\n",
      "success4\n",
      "5.jpg\n",
      "success5\n",
      "6.jpg\n",
      "success6\n",
      "7.jpg\n",
      "success7\n",
      "8.jpg\n",
      "success8\n",
      "9.jpg\n",
      "success9\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw, ImageChops\n",
    "yourPath = './data/membrane_hospital/test/label/'\n",
    "allList = os.walk(yourPath)\n",
    "for root, dirs, files in allList:\n",
    "    print(\"path：\", root)#   列出目前讀取到的路徑\n",
    "    print(\"directory：\", dirs)#   列出在這個路徑下讀取到的資料夾(第一層讀完才會讀第二層)    \n",
    "    print(\"file1：\", files)#   列出在這個路徑下讀取到的所有檔案\n",
    "    filename_list = []\n",
    "    filename_list = files\n",
    "for file_name in filename_list:\n",
    "    img_name_temp = file_name.split(\".jpg\")\n",
    "    original = Image.open('./data/membrane_hospital/test/label/'+file_name)\n",
    "    print(file_name)\n",
    "    original = original.convert(\"L\")\n",
    "    original.save('./data/membrane_hospital/test/labelpng/'+img_name_temp[0]+'.png')\n",
    "    print('success'+img_name_temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
